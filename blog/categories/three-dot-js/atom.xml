<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: three.js | Learning Three.js]]></title>
  <link href="http://learningthreejs.com/blog/categories/three-dot-js/atom.xml" rel="self"/>
  <link href="http://learningthreejs.com/"/>
  <updated>2013-08-17T13:56:40+02:00</updated>
  <id>http://learningthreejs.com/</id>
  <author>
    <name><![CDATA[Jerome Etienne]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How To Do A Procedural City In 100 Lines]]></title>
    <link href="http://learningthreejs.com/blog/2013/08/02/how-to-do-a-procedural-city-in-100lines/"/>
    <updated>2013-08-02T12:47:00+02:00</updated>
    <id>http://learningthreejs.com/blog/2013/08/02/how-to-do-a-procedural-city-in-100lines</id>
    <content type="html"><![CDATA[<p>This post explains how to code
<a href="http://www.mrdoob.com/lab/javascript/webgl/city/01/">"city"</a>
, a  demo <a href="https://twitter.com/mrdoob/status/350730133319073792">recently released</a> by
<a href="http://mrdoob.com">@mrdoob</a>.
He built a fully procedural city in 100-lines of javascript.
I found the algorithm very elegant, a simple and efficient solution.
So I made a post explaining it.</p>

<iframe width="425" height="349" src="http://www.youtube.com/embed/huTF047XVvQ" frameborder="0" allowfullscreen></iframe>




<!-- more -->


<h2>A Few Remarks on the Algorithm</h2>

<p>It always helps to get a big picture before going down to the details.
The used algorithm is <a href="http://en.wikipedia.org/wiki/Procedural_generation">fully procedural</a>.
This means the whole city is built dynamically, so no download.
It is quite elegant as well.
The algorithm to generate the city in 3d is less than 100 lines long.
What is this algo in a nutshell?
Every building is a cube, they got random size and position.
Simple enough ?
It may seem far from realism but it is ok.
The illusion is surprisingly convincing if you fly over at low altitude.</p>

<p>From a performance point of view, all buildings are merged into a single geometry,
with a single material.
As a cherry on the cake, we remove the bottom face as it is never seen.
It is very efficient as there is no shader swap and a single draw call.</p>

<p>To improve realism, we simulate ambient occlusion thru a cheap trick
using <code>vertexColor</code>.
In the city, at the street level you got shadow from the other buildings.
So the bottom of the buildings are darker than the top.
We can reproduce this effect with <code>vertexColor</code>.
We take the bottom vertices of the building and make them darker than the top.</p>

<h2>Let's get started</h2>

<p>To explain those 100 lines, we will explain it step by step:
First, we <em>"generate the base geometry for the building"</em>.
Then we use this geometry to know <em>"where to place buildings in the city"</em>.
We use some clever trick <em>"using vertexColor for ambient occlusion"</em>.
Then we <em>"merge all buildings to make a city"</em>, thus the whole city may
be drawn in a single draw call.
At the end we detail the <em>"procedural generation of building’s texture"</em>.</p>

<p>Ok so let's get started!!</p>

<h2>Generate the base Geometry for the building</h2>

<p>We build a base geometry of our building.
It will be reused several time while building the whole city.
So we build a simple CubeGeometry</p>

<p><code>javascript
var geometry = new THREE.CubeGeometry( 1, 1, 1 );
</code></p>

<p>We change the pivot point to be at the bottom of the cube, instead of its center.
So we translate the whole geometry.</p>

<p><code>javascript
geometry.applyMatrix( new THREE.Matrix4().makeTranslation( 0, 0.5, 0 ) );
</code></p>

<p>Then we remove the bottom face.
This is an optimisation.
The bottom face of a building is never seen by the viewer as it is always on the ground.
It is useless and we remove it.</p>

<p><code>javascript
geometry.faces.splice( 3, 1 );
</code></p>

<p>Now we fix the <a href="http://en.wikipedia.org/wiki/UV_mapping">UV mapping</a> for the roof face.
We set them to the single coordinate <code>(0,0)</code>.
So the roof will be the same color as a floor row.
As each face of the building is using a single texture, it can be drawn in a single draw call.
Sweet trick for optimisation.</p>

<p><code>javascript
geometry.faceVertexUvs[0][2][0].set( 0, 0 );
geometry.faceVertexUvs[0][2][1].set( 0, 0 );
geometry.faceVertexUvs[0][2][2].set( 0, 0 );
geometry.faceVertexUvs[0][2][3].set( 0, 0 );
</code></p>

<p>Ok now that we got the geometry of a single building, let's assemble buildings together to make a city!</p>

<h2>Where to place buildings in the city</h2>

<p>Well... to be honest we put them anywhere.
All is random ;)
Obviously, there are collisions but the illusion is nice if you fly at low altitude.
So first, we put the building at random position.</p>

<p><code>javascript
buildingMesh.position.x = Math.floor( Math.random() * 200 - 100 ) * 10;
buildingMesh.position.z = Math.floor( Math.random() * 200 - 100 ) * 10;
</code></p>

<p>Then we put a random rotation in Y.</p>

<p><code>javascript
buildingMesh.rotation.y = Math.random()*Math.PI*2;
</code></p>

<p>Then we change the mesh.scale to change the building size.
First how wide and deep a building can be.</p>

<p><code>javascript
buildingMesh.scale.x  = Math.random()*Math.random()*Math.random()*Math.random() * 50 + 10;
buildingMesh.scale.z  = buildingMesh.scale.x
</code></p>

<p>Then how high it is.</p>

<p><code>javascript
buildingMesh.scale.y  = (Math.random() * Math.random() * Math.random() * buildingMesh.scale.x) * 8 + 8;
</code></p>

<p>We got the position/rotation/scale of our building all set.
Now let's set its color, and how to use it to simulate shadows.</p>

<h3>Using VertexColor for Ambient Occlusion</h3>

<p><img class="right" src="/data/2013-08-02-how-to-do-a-procedural-city/screenshots/screenshot-building-with-vertexcolor-small.png"></p>

<p>In a city with lots of buildings, the bottom of the building tends to be darker than the top.
This is because the sun light hits the top harder than the bottom, at the bottom you have the shadow of another building.
This is what we call
<a href="http://http.developer.nvidia.com/GPUGems/gpugems_ch17.html">ambient occlusion</a> in graphic programming.
This concept may be implemented in various ways:
for example in screen space with <a href="http://en.wikipedia.org/wiki/Screen_space_ambient_occlusion">screen space ambient occlusion or ssao</a>
or in this
<a href="http://threejs.org/examples/webgl_geometry_minecraft_ao.html">minecraft example from three.js</a></p>

<p><img class="left" src="/data/2013-08-02-how-to-do-a-procedural-city/screenshots/screenshot-building-without-vertexcolor-small.png"></p>

<p>With three.js, it is is possible to assign a color to a vertice.
It will alter the final color of the face.
We gonna use that to simulate shadows at the bottom of building.
First we define the base colors for the part which receives lights, and the ones
which get shadows.</p>

<p><code>javascript
var light = new THREE.Color( 0xffffff )
var shadow  = new THREE.Color( 0x303050 )
</code></p>

<p>Those are constants for each building. Now we need to get a color
for this particular building. We put some randomness for variety.</p>

<p><code>javascript
var value = 1 - Math.random() * Math.random();
var baseColor = new THREE.Color().setRGB( value + Math.random() * 0.1, value, value + Math.random() * 0.1 );
</code></p>

<p>Now we need to assign the .vertexColor every vertex of every face.
If the face is a top face, we use <code>baseColor</code> of the building.
If it is a side face, we use <code>baseColor</code> multiplied by our <code>light</code>
for the top vertices and <code>shaddow</code> for the bottom vertices,
as cheap ambient occlusion.</p>

<p>```javascript
// set topColor/bottom vertexColors as adjustement of baseColor
var topColor  = baseColor.clone().multiply( light );
var bottomColor = baseColor.clone().multiply( shadow );
// set .vertexColors for each face
var geometry  = buildingMesh.geometry;  <br/>
for ( var j = 0, jl = geometry.faces.length; j &lt; jl; j ++ ) {
  if ( j === 2 ) {</p>

<pre><code>// set face.vertexColors on root face
geometry.faces[ j ].vertexColors = [ baseColor, baseColor, baseColor, baseColor ];
</code></pre>

<p>  } else {</p>

<pre><code>// set face.vertexColors on sides faces
geometry.faces[ j ].vertexColors = [ topColor, bottomColor, bottomColor, topColor ];
</code></pre>

<p>  }
}
```</p>

<p>We got a single building fully setup. Now let's make a city with many buildings.</p>

<h2>Merge all buildings to make a city</h2>

<p>To make our city, we gonna merge 20000 buildings together.
So we gonna loop and apply the above formulas for each building we add.
We have already seen that reducing draw calls is good for performance.
see <a href="/blog/2011/10/05/performance-merging-geometry/">"Performance: Merging Geometry"</a> post.
Here all buildings share the same material, so we gonna merge them all
in a single geometry.</p>

<p>```javascript
var cityGeometry= new THREE.Geometry();
for( var i = 0; i &lt; 20000; i ++ ){
  // set the position/rotation/color the building in the city
  // ...</p>

<p>  // merge it with cityGeometry - very important for performance
  THREE.GeometryUtils.merge( cityGeometry, buildingMesh );
}
```</p>

<p>Now we got a single large geometry for the whole city, let's build
a mesh from it.</p>

<p><code>javascript
// build the mesh
var material  = new THREE.MeshLambertMaterial({
  map           : texture,
  vertexColors  : THREE.VertexColors
});
var mesh = new THREE.Mesh(cityGeometry, material );
</code></p>

<p>This mesh is a whole city.
Rather cool!
Now one last step, let's explain how to make this texture.</p>

<h2>Procedural Generation of Building's Texture</h2>

<p>Here we want to generate the texture for the side of each building.
In a nutshell, it will show the floors for realism and variety.
So it alternates between row of window and row of floor.
Window rows are dark with a small noise to simulate light variations in each room.
Then we upscale texture carefully avoiding filtering.</p>

<p>First you build a canvas. Make it small, 32x64.</p>

<p><code>javascript
var canvas  = document.createElement( 'canvas' );
canvas.width  = 32;
canvas.height = 64;
var context = canvas.getContext( '2d' );
</code></p>

<p>Then you paint it in white</p>

<p><code>javascript
context.fillStyle = '#ffffff';
context.fillRect( 0, 0, 32, 64 );
</code></p>

<p>Now we need to draw on this white surface. We gonna draw floors on it.
one windows row, then a floor row and we loop.
In fact, as the face is already white, we just have to draw the window rows.
To draw the window row, we add some random to simulate lights variations in each windows.</p>

<p>```javascript
for( var y = 2; y &lt; 64; y += 2 ){
  for( var x = 0; x &lt; 32; x += 2 ){</p>

<pre><code>var value = Math.floor( Math.random() * 64 );
context.fillStyle = 'rgb(' + [value, value, value].join( ',' )  + ')';
context.fillRect( x, y, 2, 1 );
</code></pre>

<p>  }
}
```</p>

<p><img class="right" src="/data/2013-08-02-how-to-do-a-procedural-city/screenshots/screenshot-texture-smoothing-small.png"></p>

<p>Now we got the texture... just it is super small, 32, 64
We need to increase its resolution. But lets be careful.
By default when you increase the resolution, you get a smoothed result, so it may easily appears blurry.
See on the right side, it doesn't look good...
To avoid this artefact, we disable <code>.imageSmoothedEnabled</code> on each plateform.
You can see the result on the left.
The blurry effect is no more.
It is as sharp as the original but with a better resolution.
Ok now lets code exactly that. First we create the large canvas of 1024 by 512.</p>

<p><code>javascript
var canvas2 = document.createElement( 'canvas' );
canvas2.width = 512;
canvas2.height  = 1024;
var context = canvas2.getContext( '2d' );
</code></p>

<p>We disable the smoothing</p>

<p><code>javascript
context.imageSmoothingEnabled   = false;
context.webkitImageSmoothingEnabled = false;
context.mozImageSmoothingEnabled  = false;
</code></p>

<p>Now we just have to copy the small canvas into the big one.</p>

<p><code>javascript
context.drawImage( canvas, 0, 0, canvas2.width, canvas2.height );
</code></p>

<p>Then all we need to do is to actually build the <code>THREE.Texture</code>.
We set the anisotropie to a high number to get better result.
see <a href="http://blog.tojicode.com/2012/03/anisotropic-filtering-in-webgl.html">tojiro on anisotropy</a> for detail.</p>

<p><code>javascript
var texture   = new THREE.Texture( generateTexture() );
texture.anisotropy  = renderer.getMaxAnisotropy();
texture.needsUpdate = true;
</code></p>

<p>This was the last step. Now, you know how to do a procedural city
in webgl with three.js. Rather cool!
As a summary here is the whole code put together.</p>

<h2>The Whole Code</h2>

<p>Let's put all that together. Here is the whole code commented.</p>

<p>```javascript
// build the base geometry for each building
var geometry = new THREE.CubeGeometry( 1, 1, 1 );
// translate the geometry to place the pivot point at the bottom instead of the center
geometry.applyMatrix( new THREE.Matrix4().makeTranslation( 0, 0.5, 0 ) );
// get rid of the bottom face - it is never seen
geometry.faces.splice( 3, 1 );
geometry.faceVertexUvs[0].splice( 3, 1 );
// change UVs for the top face
// - it is the roof so it wont use the same texture as the side of the building
// - set the UVs to the single coordinate 0,0. so the roof will be the same color
//   as a floor row.
geometry.faceVertexUvs[0][2][0].set( 0, 0 );
geometry.faceVertexUvs[0][2][1].set( 0, 0 );
geometry.faceVertexUvs[0][2][2].set( 0, 0 );
geometry.faceVertexUvs[0][2][3].set( 0, 0 );
// buildMesh
var buildingMesh= new THREE.Mesh( geometry );</p>

<p>// base colors for vertexColors. light is for vertices at the top, shaddow is for the ones at the bottom
var light   = new THREE.Color( 0xffffff )
var shadow  = new THREE.Color( 0x303050 )</p>

<p>var cityGeometry= new THREE.Geometry();
for( var i = 0; i &lt; 20000; i ++ ){</p>

<pre><code>// put a random position
buildingMesh.position.x = Math.floor( Math.random() * 200 - 100 ) * 10;
buildingMesh.position.z = Math.floor( Math.random() * 200 - 100 ) * 10;
// put a random rotation
buildingMesh.rotation.y = Math.random()*Math.PI*2;
// put a random scale
buildingMesh.scale.x    = Math.random() * Math.random() * Math.random() * Math.random() * 50 + 10;
buildingMesh.scale.y    = (Math.random() * Math.random() * Math.random() * buildingMesh.scale.x) * 8 + 8;
buildingMesh.scale.z    = buildingMesh.scale.x

// establish the base color for the buildingMesh
var value   = 1 - Math.random() * Math.random();
var baseColor   = new THREE.Color().setRGB( value + Math.random() * 0.1, value, value + Math.random() * 0.1 );
// set topColor/bottom vertexColors as adjustement of baseColor
var topColor    = baseColor.clone().multiply( light );
var bottomColor = baseColor.clone().multiply( shadow );
// set .vertexColors for each face
var geometry    = buildingMesh.geometry;        
for ( var j = 0, jl = geometry.faces.length; j &lt; jl; j ++ ) {
    if ( j === 2 ) {
        // set face.vertexColors on root face
        geometry.faces[ j ].vertexColors = [ baseColor, baseColor, baseColor, baseColor ];
    } else {
        // set face.vertexColors on sides faces
        geometry.faces[ j ].vertexColors = [ topColor, bottomColor, bottomColor, topColor ];
    }
}
// merge it with cityGeometry - very important for performance
THREE.GeometryUtils.merge( cityGeometry, buildingMesh );
</code></pre>

<p>}</p>

<p>// generate the texture
var texture     = new THREE.Texture( generateTexture() );
texture.anisotropy  = renderer.getMaxAnisotropy();
texture.needsUpdate = true;</p>

<p>// build the mesh
var material    = new THREE.MeshLambertMaterial({</p>

<pre><code>map     : texture,
vertexColors    : THREE.VertexColors
</code></pre>

<p>});
var cityMesh = new THREE.Mesh(cityGeometry, material );</p>

<p>function generateTexture() {</p>

<pre><code>// build a small canvas 32x64 and paint it in white
var canvas  = document.createElement( 'canvas' );
canvas.width    = 32;
canvas.height   = 64;
var context = canvas.getContext( '2d' );
// plain it in white
context.fillStyle   = '#ffffff';
context.fillRect( 0, 0, 32, 64 );
// draw the window rows - with a small noise to simulate light variations in each room
for( var y = 2; y &lt; 64; y += 2 ){
    for( var x = 0; x &lt; 32; x += 2 ){
        var value   = Math.floor( Math.random() * 64 );
        context.fillStyle = 'rgb(' + [value, value, value].join( ',' )  + ')';
        context.fillRect( x, y, 2, 1 );
    }
}

// build a bigger canvas and copy the small one in it
// This is a trick to upscale the texture without filtering
var canvas2 = document.createElement( 'canvas' );
canvas2.width   = 512;
canvas2.height  = 1024;
var context = canvas2.getContext( '2d' );
// disable smoothing
context.imageSmoothingEnabled       = false;
context.webkitImageSmoothingEnabled = false;
context.mozImageSmoothingEnabled    = false;
// then draw the image
context.drawImage( canvas, 0, 0, canvas2.width, canvas2.height );
// return the just built canvas2
return canvas2;
</code></pre>

<p>}
```</p>

<h2>threex.proceduralcity extension</h2>

<p>As usual, this code is gathered in easy-to-reuse threex package,
<a href="https://github.com/jeromeetienne/threex.proceduralcity">threex.proceduralcity</a>.
It makes stuff super simple, just create an instance and it will return a <code>THREE.Mesh</code>.</p>

<p><code>javascript
var city  = new THREEx.ProceduralCity()
scene.add(city)
</code></p>

<p>The <a href="http://jeromeetienne.github.io/threex.proceduralcity/examples/demo.html">demo live</a>
contains this city plus a ground, a first person control and a fog.
This is rather cool result for such a small effort.</p>

<h2>Conclusion</h2>

<p>So now you know how to generate a whole city in 100 lines.
No download.
Rather clever algorithm.
I hope you learned from it,
it contains many tricks that you can reused in your own demos.</p>

<p>That's all for today! Have fun :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Monitor Rendering Performance Within Three.js]]></title>
    <link href="http://learningthreejs.com/blog/2013/06/25/monitor-rendering-performance-within-threejs/"/>
    <updated>2013-06-25T10:58:00+02:00</updated>
    <id>http://learningthreejs.com/blog/2013/06/25/monitor-rendering-performance-within-threejs</id>
    <content type="html"><![CDATA[<p>This post is about monitoring rendering performance within three.js.
It presents a small standalone extension called <code>threex.rendererstats</code>.
It collect information from three.js renderer and display it live.
It is very usefull to diagnose performance issues while developping.
The API is exactly the same as <a href="http://github.com/mrdoob/stats.js">stats.js</a>
so it is easy for you to include in your own stuff.</p>

<iframe width="425" height="349" src="http://www.youtube.com/embed/UXWpnANajDk" frameborder="0" allowfullscreen></iframe>




<!-- more -->


<h2>What Is It ?</h2>

<p><img class="right" src="/data/2013-06-13-monitor-rendering-performance-within-threejs/screenshot-rendererstats.png"></p>

<p><a href="http://github.com/jeromeetienne/threex.rendererstats">threex.rendererstats</a> collects information
about three.js renderer and display it realtime on your screen.
It is released under MIT license and is available on
<a href="http://github.com/jeromeetienne/threex.rendererstats">github</a>.
See a screenshot on the right.</p>

<p><a href='http://jeromeetienne.github.io/threex.rendererstats/examples/basic.html' target='_blank'><input type="button" value='Try Live Demo!' style='font-size:400%;' /></a></p>

<p><img class="left" src="/data/2013-06-13-monitor-rendering-performance-within-threejs/screenshot-stats.png" width="240"></p>

<p>It is inpired from
<a href="http://github.com/mrdoob/stats.js">stats.js</a> by
<a href="http://mrdoob.com">mrdoob</a>.
See a screenshot on the left.
Webgl renderer keeps some internal statistics on the scene being renderered and update it at every frame.
It is accessible in a property <code>.info</code>.
threex.rendererstats just gather this information and display it nicely on your screen.</p>

<h2>How Is It Useful ?</h2>

<p>It is a very nice tool to monitor performances of WebGL rendering.
As it is updated realtime, you can identify performance issues at various moments within your game
We have seen canvas inspection recently in
<a href="http://learningthreejs.com/blog/2013/04/05/debugging-with-chromes-canvas-inspection/">Debugging With Chrome’s Canvas Inspection</a>.
<a href="http://learningthreejs.com/blog/2013/04/05/debugging-with-chromes-canvas-inspection/">canvas inspection</a>
is directly at webgl level. threex.rendererstats remains at three.js level to give you another kind
of information on the renderer.</p>

<p>Lets details those information
There is 2 sections one for the memory, another for the renderer.
For the memory, you got</p>

<ul>
<li><code>info.memory.geometry</code> : number of geometry currently in memory</li>
<li><code>info.memory.programs</code> : number of shaders currently in memory</li>
<li><code>info.memory.texture</code> : number of texture currently in memory</li>
</ul>


<p>For the render, you got</p>

<ul>
<li><code>info.render.calls</code> : number of draw calls currently used to render</li>
<li><code>info.render.vertices</code> : number of vertices currently rendered</li>
<li><code>info.render.faces</code> : number of triangles currently renderered</li>
<li><code>info.render.points</code> : number of particles currently rendered</li>
</ul>


<h2>How To Use It ?</h2>

<p>first, include <code>threex.rendererstats.js</code> with the usual <code>&lt;script&gt;</code> tag.</p>

<p>```html</p>

<script src='threex.rendererstats.js'></script>


<p>```</p>

<p>then you initialize the object.</p>

<p><code>javascript
var rendererStats   = new THREEx.RendererStats()
</code></p>

<p>You likely need to position it on the page with css.
You may use something along this line</p>

<p><code>javascript
rendererStats.domElement.style.position = 'absolute'
rendererStats.domElement.style.left = '0px'
rendererStats.domElement.style.bottom   = '0px'
document.body.appendChild( rendererStats.domElement )
</code></p>

<p>finally you update it at every frame in your rendering loop or when you do <code>renderer.render()</code></p>

<p><code>javascript
rendererStats.update(renderer);
</code></p>

<p>And you are done. Quite easy to include! Now you can monitor your own three.js scenes.</p>

<h2>Conclusion</h2>

<p>We have seen how to monitor performance information withing three.js.
How to display and use the statistics collected by <code>THREE.WebGLRenderer</code>
itself.
The information may appear a bit raw but it is live.
So unexpected performance changes can be detected very early.</p>

<p>That's all for today! have fun :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mixing HTML pages inside your WebGL]]></title>
    <link href="http://learningthreejs.com/blog/2013/04/30/closing-the-gap-between-html-and-webgl/"/>
    <updated>2013-04-30T11:11:00+02:00</updated>
    <id>http://learningthreejs.com/blog/2013/04/30/closing-the-gap-between-html-and-webgl</id>
    <content type="html"><![CDATA[<p>Wouldn't that be cool if we were able to mix normal web pages in our webgl? To interact with them as we usually do? to view them,  to click on them... To scroll, to hover or even to type in input tags.
Oh yeah it would be so great! We, webgl people, are currently an isolated Island in the web world.  Being able to mix with normal page would give us access to so much interactive content.
In this post,  we gonna see how to do exactly this: how to seamlessly mix normal DOM elements in our webgl scene.  They will actually  appear as part of the 3d scene. Don't worry it is surprisingly easy with three.js.</p>

<center>
  <iframe width="425" height="349" src="http://www.youtube.com/embed/ScZcUEDGjJI" frameborder="0" allowfullscreen></iframe>
</center>




<!-- more -->


<h2>Demo of a youtube browser mixed in WebGL</h2>

<p><img class="right" src="/data/2013-04-30-closing-the-gap-between-html-and-webgl/screenshots/navigation-bar-small.png"></p>

<p>First let's see the result in action. Here is a demo I did to show all the videos I have done for this blog.
<a href="http://jeromeetienne.github.io/videobrowser4learningthreejs">Try it out</a>!
It shows a 3d scene with a tv set and three characters sitting on grass.</p>

<p><a href='http://jeromeetienne.github.io/videobrowser4learningthreejs/' target='_blank'><input type="button" value='Try Learningthree.js video browser!' style='font-size:200%' /></a>
<a href='http://learningthreejs.com/data/2013-04-30-closing-the-gap-between-html-and-webgl/index.html' target='_blank'><input type="button" value='Try Demo!' style='font-size:200%' /></a></p>

<p>The key point is on the tvset screen. This is an actual YouTube player. Not me emulating it, this is the real thing! You can access it anytime from the blog navigation bar as
you can see on the right.
This
<a href="http://jeromeetienne.github.io/videobrowser4learningthreejs">demo</a>
is pretty cool no? Now let's see how to do this.</p>

<h2>Let's Get Started</h2>

<p>DOM elements are all about flat 2d rectangles. In
<a href="http://threejs.org/">three.js</a>
, such a thing is called a
<a href="https://github.com/mrdoob/three.js/blob/master/src/extras/geometries/PlaneGeometry.js">THREE.PlaneGeometry</a>.
So let's try to map a
<a href="https://developer.mozilla.org/en/docs/DOM/element">dom element</a>
to a
<a href="https://github.com/mrdoob/three.js/blob/master/src/extras/geometries/PlaneGeometry.js">THREE.PlaneGeometry</a>.
Their position and rotation must match.
The goal is to make them appear as one thus the viewer can't distinguish them.</p>

<p>So first, how to orientate a dom element, would you ask?
Simple we gonna use a feature introduced by HTML5, called
<a href="http://www.w3.org/TR/css3-transforms/">css 3D transformation</a>.
Here are some <a href="http://www.html5rocks.com/en/tutorials/3d/css/">tutorials</a>
<a href="http://desandro.github.io/3dtransforms/">about</a>
<a href="https://developer.mozilla.org/en-US/docs/CSS/Tutorials/Using_CSS_transforms">it</a>.
css3d is done for this exact purpose, to position and rotate a DOM element in 3d.</p>

<p><img class="right" src="/data/2013-04-30-closing-the-gap-between-html-and-webgl/screenshots/grid-only-small.png"></p>

<p>Good News! three.js can already render things using this technology.
 It is called <a href="https://github.com/mrdoob/three.js/blob/master/examples/js/renderers/CSS3DRenderer.js">THREE.CSS3DRenderer</a>.
See <a href="http://threejs.org/examples/css3d_molecules.html">various</a>
<a href="http://threejs.org/examples/css3d_periodictable.html">examples</a>
of
<a href="http://threejs.org/examples/css3d_youtube.html">its</a>
<a href="http://threejs.org/examples/css3d_panorama.html">usage</a>
in three.js <code>/examples</code>.
Now we need to put the same plane on both renderers, WebGL Renderer and CSS3D Renderer.
Here is the code for the plane in
<a href="https://github.com/mrdoob/three.js/blob/master/src/renderers/WebGLRenderer.js">WebGLRenderer</a>
, wireframe with segments to see thru.</p>

<p><code>javascript
// create the plane mesh
var material = new THREE.MeshBasicMaterial({ wireframe: true });
var geometry = new THREE.PlaneGeometry();
var planeMesh= new THREE.Mesh( geometry, material );
// add it to the WebGL scene
glScene.add(planeMesh);
</code></p>

<p>Now that we got the plane in place, here is the code for the DOM element in css 3d.
Notice how we reference the same position and rotation as the <code>planeMesh</code>, thus
they will move together.</p>

<p><code>javascript
// create the dom Element
var element = document.createElement( 'img' );
element.src = 'textures/sprites/ball.png';
// create the object3d for this element
var cssObject = new THREE.CSS3DObject( element );
// we reference the same position and rotation
cssObject.position = planeMesh.position;
cssObject.rotation = planeMesh.rotation;
// add it to the css scene
cssScene.add(cssObject);
</code></p>

<p><img class="right" src="/data/2013-04-30-closing-the-gap-between-html-and-webgl/screenshots/grid-css-small.png"></p>

<p>All seems to go well.
We got the same plane in css and webgl. Now we need to see the dom element behind the webgl plane.
To do this, let's use webgl renderer and css3d renderer together on the same page.</p>

<p>We use stylesheet to put css renderer exactly behind the webgl one.
Thus they look the same to the viewer, as you can see on the right.
Use the following line to obtain the same result.</p>

<p><code>javascript
var cssRenderer = new THREE.CSS3DRenderer();
cssRenderer.setSize( window.innerWidth, window.innerHeight );
cssRenderer.domElement.style.position = 'absolute';
cssRenderer.domElement.style.top = 0;
</code></p>

<p><img class="right" src="/data/2013-04-30-closing-the-gap-between-html-and-webgl/screenshots/object-inmiddle-small.png">
<img class="left" src="/data/2013-04-30-closing-the-gap-between-html-and-webgl/screenshots/object-infront-small.png"></p>

<p>We are in good shape but not yet done. We still need to make both react as if they were one.
What happens if we add a torus 3d object in front of webgl plane? As you can see on the
left, it looks Ok.
What if we put this object behind it? Hmm not so good. As you can see on the right, the object
is behind the Plane,
but it is in front of the dom element. It should appear as if the torus were behind but it doesn't.
Why's that? It is due to the webgl
<a href="http://en.wikipedia.org/wiki/Z-buffering">z-buffer</a>.</p>

<p>It displays our torus because it thinks the torus is closer to the camera than the DOM element.
It's not aware that our webgl plane should act as a see-thru to make our css3d visible.
So nothing behind our webgl plane should be displayed.
How to fix this, you would ask? We're gonna use a tricky part of webgl: the blending.</p>

<h2>Blending them together</h2>

<p>What is blending ? It is the way to determine the color of a pixel when you add a
new pixel (fragment in technical terms).
So when doing blending, we use a blend function to combine the colors from both the
existing and the new fragments to make an entirely new fragment.</p>

<p>It is a weird beast using several WebGL calls and many equations. The total number of possibilities is scary :)
A complete explanation of blending is way out of scope of this post. For more detail, see
<a href="http://www.amazon.com/WebGL-Beginners-Guide-Diego-Cantor/dp/184969172X">"WebGL Beginner's Guide"</a>
from
<a href="http://blog.tojicode.com/">Brandon Jones</a>, a great book to start with raw WebGL.
To get a feel of blending,  you can play with them in
<a href="http://threejs.org/examples/webgl_materials_blending_custom.html">this example</a>.</p>

<p><img class="right" src="/data/2013-04-30-closing-the-gap-between-html-and-webgl/screenshots/object-behind-small.png"></p>

<p>The one which interest us is called <code>THREE.NoBlending</code>.
When drawing the face, it will completely ignore the color below and set it to the color of the face.
So if we put our face color to black aka <code>(0, 0, 0)</code> and opacity to <code>0</code>, we gonna obtained what we want.
The plane will act as a see-thru to the dom element below. Here is how you initialize your material.</p>

<p><code>javascript
var material    = new THREE.MeshBasicMaterial();
material.color.set('black')
material.opacity    = 0;
material.blending   = THREE.NoBlending;
// any mesh using this material will act as a see-thru to the css renderer
</code></p>

<p>Then we are done ! We got a actual dom element seamlessly integrated in our webgl scene!  Let's pet our back,  i think this is an important step!</p>

<h2>HTML And WebGL Sitting Together In A Tree ?</h2>

<p>Well, not quite unfortunatly...
WebGL is 3d inside a <a href="http://en.wikipedia.org/wiki/Canvas_element">canvas element</a>
and a canvas is a black box from the html page point of view.
You can't bind <a href="http://en.wikipedia.org/wiki/DOM_events">DOM events</a> inside canvas.
You can't have
<a href="http://en.wikipedia.org/wiki/Style_sheet_(web_development)">stylesheet</a>
to change canvas content.
You can't put dom elements inside your canvas.
Those two don't talk to each other.</p>

<p>Unfortunatly it isn't all pink, WebGL and HTML aren't really merged.
This is only a nice trick. It has some limitations.
For example, the dom element is rotated using <a href="http://example.com/TODO">css 3d</a>.
This is a fairly new technology.
So you may hit bugs.</p>

<p>Moreover, it only appears as a part of 3d... but this remains plain DOM.
So it doesn't benefit from webgl specific display.
For example, it is impossible to get
<a href="http://example.com/TODO">post processing</a>
on the dom element.
Indeed, this technic is applied in 2d on the rendered scene and the DOM element is not in it.
Additionally the dom element won't share the lighting as the rest of your webgl scene.
Nevertheless, <a href="http://example.com/TODO">css shader</a> allows you to apply shader on normal DOM element,
so it may be possible to make a coherent lighting.
The web is so beautiful nowadays!</p>

<h3>Conclusion</h3>

<p>Congratulations guys! You can now mix html pages with your webgl content. You have learned how to close the gap between HTML and WebGL. It is a new way to experience and to interact with webgl 3d.</p>

<p>I love this new trick.
I've been trying to make webgl easier for while now.
My strategy has been to make it closer to what webdevs know today,
copying <a href="http://jeromeetienne.github.com/tquery/">jQuery API on top of three.js</a>,
emulating <a href="http://learningthreejs.com/blog/2012/01/17/dom-events-in-3d-space/">dom events inside webgl scene</a>
or even making <a href="http://learningthreejs.com/blog/2012/02/27/linkify-tquery-extension/">3d text act as web links</a>.
To integrate actual web pages inside webgl scene definitly matches this vibe!</p>

<p>That's all for today, have fun :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Debugging With Chrome's Canvas Inspection]]></title>
    <link href="http://learningthreejs.com/blog/2013/04/05/debugging-with-chromes-canvas-inspection/"/>
    <updated>2013-04-05T09:15:00+02:00</updated>
    <id>http://learningthreejs.com/blog/2013/04/05/debugging-with-chromes-canvas-inspection</id>
    <content type="html"><![CDATA[<p>This post will present to you how to debug your webgl with  chrome's canvas inspection.
This is an experimental feature available in chrome devtools.
It gives you all the WebGL calls which are done in your webgl scene.
So it helps if you actually know some raw WebGL :)
In anycase you can see it being replayed call by calls, which is uber cool.</p>

<center>
  <iframe width="425" height="349" src="http://www.youtube.com/embed/837O1YloCRc" frameborder="0" allowfullscreen></iframe>
</center>




<!-- more -->


<h2>Let's get started</h2>

<p>As it is an experimental feature, you first need to enable it.
First let's enable devtool experiment: enter "chrome://flags" url
in your chrome location bar. There you enable "Enable Developer Tools experiments"
and relaunch chrome.</p>

<p><img src="/data/2013-04-05-debugging-with-chromes-canvas-inspection/screenshots/devtools-enable-experiments.png"></p>

<p><img class="right" src="/data/2013-04-05-debugging-with-chromes-canvas-inspection/screenshots/devtools-settings-gear.png" width="160" height="120"></p>

<p>Now that you got the Developer Tools Experiments enabled, let's enable
'Canvas Inpection' in particular. Click on the little gear on bottom right
of devtools. The one you can see on the right.</p>

<p><img src="/data/2013-04-05-debugging-with-chromes-canvas-inspection/screenshots/devtools-settings-panel.png"></p>

<p>It will open the settings panel you see above.
Now, select experiment from the left menu, enable 'Canvas Inpection' and you are done.
Rather clumsy but this is an experiment after all :)</p>

<h2>How to use it</h2>

<p>Now that it is enabled, let's see how to use it.
First let's go on the "profile" tab of devtools. We can see "Capture Canvas Frame", this is the one we gonna use.</p>

<p><img src="/data/2013-04-05-debugging-with-chromes-canvas-inspection/screenshots/devtools-capture-canvas-frame.png"></p>

<p>Let's enable it and load a page with WebGL.
As an example, i will use <a href="http://mmo3d.jit.su/montains">mmo3d</a>. It is a multiplayer game
in webgl. It is very hackable so other people can easily do their own world. Let's talk about
that later. For now, lets click 'start' and capture a frame :)</p>

<h2>Captured frames</h2>

<p>After that you should obtain the following. You got the actual game on the left.
and you recognise developer tools on the right.</p>

<p><img src="/data/2013-04-05-debugging-with-chromes-canvas-inspection/screenshots/devtools-capture-example-resized.png"></p>

<p>For every frame you capture, you will get a trace log of each webgl call which has been done during this frame.
Above there is a replay window where you can actually see the scene as it is drawn step by step.
Thus you can check the order of your calls. It can be usefull when you debug transparency for example.
Watch for the draw calls, they got huge overhead and should be limited if possible.</p>

<h2>Conclusion</h2>

<p>As it is pure webgl, and not at three.js level, it helps if you know raw WebGL. For that, i suggest
you to read a book on the subject. Personnaly i
like
<a href="http://www.amazon.com/WebGL-Beginners-Guide-Diego-Cantor/dp/184969172X">"WebGL Beginner's Guide"</a>
by
<a href="http://blog.tojicode.com/">Brandon Jones</a>.
WebGL may be complex at times, and having cool debug tools help being more efficient.
You can see the excelent paul irish doing a
<a href="http://www.youtube.com/watch?v=FY5iiuQRyEE&amp;feature=youtu.be&amp;t=8m23s">presentation</a>
what you can do with canvas inspector.</p>

<p>That's all folks. Have Fun!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Move a Cube With Your Head or Head-Tracking with WebGL]]></title>
    <link href="http://learningthreejs.com/blog/2013/03/12/move-a-cube-with-your-head/"/>
    <updated>2013-03-12T13:28:00+01:00</updated>
    <id>http://learningthreejs.com/blog/2013/03/12/move-a-cube-with-your-head</id>
    <content type="html"><![CDATA[<p>This post is about head tracking and how to use it in 3D.
It is surprisingly easy to do with the suitable libraries.
We will experiment with
<a href="https://github.com/auduno/headtrackr">headtrackr.js</a> and
<a href="http://github.com/mrdoob/three.js/">three.js</a>.
<a href="https://github.com/auduno/headtrackr">headtrackr.js</a>
is a nice library from
<a href="https://github.com/auduno">auduno</a> to do head tracking in the browser.
You will learn how to do head tracking in webgl in only 20lines of javascript.
I love the web and how easy it is :)</p>

<h2>tl;dr; links</h2>

<ul>
<li>For a simple example. see the <a href="http://jeromeetienne.github.com/tquery/plugins/headtrackr/examples/index.html">"move a cube with your head"</a> demo</li>
<li>To mess with the code now without any installation, see this <a href="http://jsfiddle.net/jetienne/tSQQ8/">jsfiddle example</a></li>
<li>for an attempt to make 3d more immersive by using head tracking, see this <a href="http://jeromeetienne.github.com/tquery/plugins/headtrackr/examples/demo.html">demo</a></li>
</ul>


<center>
    <iframe width="425" height="349" src="http://www.youtube.com/embed/gnVfqfjXxmM" frameborder="0" allowfullscreen></iframe>
</center>




<!-- more -->


<h2>WebRTC is great!</h2>

<p>WebRTC starts to get traction. I love that! We have seen
<a href="http://www.webrtc.org/">WebRTC</a>
and
<a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html">getUserMedia</a>
several times in the past: in
<a href="http://learningthreejs.com/blog/2012/05/15/punch-a-doom-character-in-augmented-reality/">"Punch a Doom Character in Augmented Reality"</a>
post, in
<a href="http://learningthreejs.com/blog/2012/02/07/live-video-in-webgl/">"Fun With Live Video in WebGL"</a>
post and
<a href="http://learningthreejs.com/blog/2012/05/02/augmented-reality-3d-pong/">"Augmented Reality 3D Pong"</a>
post.
It is
<a href="http://www.webrtc.org/blog/seeyouontheweb">already in chrome stable</a>
, and will be in firefox
<a href="https://hacks.mozilla.org/2012/11/progress-update-on-webrtc-for-firefox-on-desktop/">real soon</a>.
They already
<a href="https://hacks.mozilla.org/2013/02/hello-chrome-its-firefox-calling/">talk to each other</a>.
Here we don't need the network part of webrtc.
We only need get the webcam video, so
<a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html">getUserMedia</a>
is enougth. It is in
<a href="http://www.opera.com/browser/">opera 12</a>
too as you can read
<a href="http://dev.opera.com/articles/view/head-tracking-with-webrtc/">here</a>.</p>

<p><a href="https://github.com/auduno">auduno</a> is part of
<a href="http://opera.com">Opera</a> team.
He wrote it as a demo for
<a href="http://www.opera.com/browser/">opera 12</a>
release  which contained
<a href="http://dev.w3.org/2011/webrtc/editor/getusermedia.html">getUserMedia</a>.
For more info on the library, <a href="https://github.com/auduno">auduno</a>
blogged
about internals of
<a href="https://github.com/auduno/headtrackr">his library</a>. You can find details in his
<a href="http://auduno.tumblr.com/post/25125149521/head-tracking-with-webrtc">blog post</a>.
Additionnal info are available in the
<a href="http://auduno.github.com/headtrackr/documentation/reference.html">reference documentation</a>.
Some examples are already in three.js, like
<a href="http://auduno.github.com/headtrackr/examples/targets.html">targets</a>
or
<a href="http://www.shinydemos.com/facekat/">facekat</a>.</p>

<h2>Demo Time !!</h2>

<p><img class="left" src="/data/2013-03-12-playing-with-headtrackr-dot-js/screenshots/screenshot-box3d-small.png">
As usual we did a plugin for
<a href="http://jeromeetienne.github.com/tquery">tQuery API</a>
to make it easy to use in our environement.
One can find 2 examples for it:
A <a href="http://jeromeetienne.github.com/tquery/plugins/headtrackr/examples/index.html">educational example</a>
where your heads controls a box in 3d.
For best result, <em>make sure your face is well and evenly lighted</em></p>

<p><img class="right" src="/data/2013-03-12-playing-with-headtrackr-dot-js/screenshots/screenshot-demo-small.png">
Another <a href="http://jeromeetienne.github.com/tquery/plugins/headtrackr/examples/demo.html">demo</a>
where the camera follows your head.
The whole scene moves as you move your head, providing quite an immersive experience.
You can play with it <a href="http://jsfiddle.net/jetienne/tSQQ8/">thru jsfiddle</a> too.</p>

<iframe style="width: 100%; height: 300px" src="http://jsfiddle.net/jetienne/tSQQ8/embedded/" allowfullscreen="allowfullscreen" frameborder="0"></iframe>


<h2>Let's Get Started</h2>

<p>Ok now lets see how to use this library with
<a href="http://jeromeetienne.github.com/tquery">tQuery API</a>.
First, we include the <code>tquery.headtrackr</code> files in your code.
tQuery plugins supports
<a href="http://requirejs.com">require.js</a>.
It makes dependancies much easier to handle. <code>tquery.headtrackr</code> is no exception, so to include it you can do</p>

<p>```javascript
require(['tquery.headtrackr'], function(){</p>

<pre><code>// Your code ...    
</code></pre>

<p>});
```</p>

<p>Or if you use the good old <code>&lt;script&gt;</code>, do something like that
to include
<a href="https://github.com/auduno/headtrackr">headtrackr.js</a> itself, the library which handle the head tracking. Then you just include the plugin itself, and you are done.</p>

<p>```html</p>

<script src="headtrackr.js"></script>


<script src="tquery.headtrackr.js"></script>


<p>```</p>

<h3>Start Tracking Heads</h3>

<p>First, you instanciate the object with this simple line.
You can pass various options to <code>.createHeadtrackr(opts)</code>.
Here, <code>opts</code> is an
<a href="https://developer.mozilla.org/en-US/docs/JavaScript/Reference/Global_Objects/Object">Object</a>
with those properties</p>

<ul>
<li><strong>opts.width :</strong> width of the image containing the face. default to 320px</li>
<li><strong>opts.height :</strong> height of the image containing the face. default to 240px</li>
<li><strong>opts.headtrackrOpts :</strong> options passed directly to headtrackr.js. default to <code>{}</code></li>
</ul>


<p><code>javascript
var headTracker = tQuery.createHeadtrackr();
</code></p>

<p>Default are reasonable, so chances are you dont need to specify anything. To start tracking the head on the webcam, just do the following</p>

<p><code>javascript
headTracker.start();
</code></p>

<p>It is possible to stop it with <code>.stop()</code> or to reset it via <code>.reset()</code>.</p>

<h3>Debug View is Cool For User Feedback</h3>

<p><img class="right" src="/data/2013-03-12-playing-with-headtrackr-dot-js/screenshots/screenshot-debugview-small.png">
If you wish enable the debugView, aka the little visualisation the headtracker result.
It gives feedback to the user on what is happening.
Thus the user can move his head accordingly or to change lighting of the room.</p>

<p><code>
headTracker.debugView(true);
</code></p>

<h3>Face Position Notified thru Events</h3>

<p>When a face is found, events are dispatched to notify the detected positions.</p>

<p>```
headTracker.addEventListener("found", function(event){</p>

<pre><code>// Your code ...
</code></pre>

<p>});
```</p>

<p><code>event</code> contains normalized coordinates of the detected face.
They use the same axis as WebGL.
If the head is on the center, <code>event.x</code> and <code>event.y</code> will be 0.
And if the head is vertical, <code>event.angle</code> is 0. More precisely</p>

<ul>
<li><code>.x</code> and <code>.y</code> : It is the center position. it varies from [-1,+1], from left to right
and bottom to top.</li>
<li><code>.width</code> and <code>.height</code>: the width and height :) If it is half of whole image, it is equal to 1.</li>
<li><code>.angle</code>: the Z rotation of the detected head. It is in radian as usual.</li>
<li><code>.headtrackrEvent</code>: the original facetrackingEvent event from
<a href="https://github.com/auduno/headtrackr">headtrackr.js</a>
(see
<a href="http://auduno.github.com/headtrackr/documentation/reference.html">reference</a>
)</li>
</ul>


<h2>Head tracking... Kesaco ?</h2>

<p>Head tracking is a <a href="http://example.com">well known concept</a>. One can find
<a href="http://www.youtube.com/watch?v=bBQQEcfkHoE">head tracking on ipad</a>.
One can find <a href="http://www.youtube.com/watch?v=Jd3-eiid-Uw">head tracking on wii</a>.
They got impressive result using the informations from the <a href="http://en.wikipedia.org/wiki/Wii_Remote">wiimote</a> or even the <a href="http://example.com">device orientation</a>.
With the <a href="http://en.wikipedia.org/wiki/Kinect">kinect</a>, they even
track the <a href="http://example.com">features</a> of the face itself (e.g. mouth, noze, eyes etc...)</p>

<p>In our case, we use the image from the webcam.
Unfortunatly face localisation from an image isn't exactly 100% accurate to say the least :)
See <a href="http://auduno.github.com/headtrackr/examples/targets.html">here</a>,
this is the same demo as the
<a href="http://www.youtube.com/watch?v=Jd3-eiid-Uw">wii one</a>
or the
<a href="http://www.youtube.com/watch?v=bBQQEcfkHoE">ipad one</a>.
Yet the result isn't as convincing.
With <a href="https://github.com/auduno/headtrackr">headtrackr.js</a> and
<a href="http://webrtc.org">webrtc</a>
, we use only the webcam in a uncontrolled environement.
So the accuracy is in consequences.</p>

<p>You can improve efficiency by following a few simples advices:
Avoid hats or a too crazy haircut. Being bold with a beard doesn't help :)
Make sure your face is well and evenly lighted and you should be fine.</p>

<h2>Conclusion</h2>

<p>In this post, we have seen it is now possible to do head tracking in a web browser !!
Impressive if you ask me!
Even better, it is easy if you use suitable libraries. Coupled with
<a href="http://github.com/mrdoob/three.js/">three.js</a>
and
<a href="http://jeromeetienne.github.com/tquery">tQuery API</a>,
it is possible provide new immersive experience in
<a href="http://jsfiddle.net/jetienne/tSQQ8/">20lines of javascript</a>.
Im so excited.
This kind of things was academic research 5 years ago, and now everybody can easily use it.
We will likely do more with
<a href="https://github.com/auduno/headtrackr">headtrackr.js</a>.
This is a very nice library with lots of possibilities.
For example, one can use it the head as a game controller, or in a artistic exposition. Stay tuned!</p>

<p>That's all folks, have fun :)</p>
]]></content>
  </entry>
  
</feed>
